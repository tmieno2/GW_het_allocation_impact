```{r setup, include=FALSE}
library(knitr)
# library(here)
library(modelsummary)
library(data.table)
library(tidyverse)
library(maps)
library(flextable)
library(sf)
library(RColorBrewer)
library(patchwork)
library(plotly)
library(ggplot2)
library(ggthemes)
library(ggpubr)
library(viridis)
library(grid)
library(gridExtra)
library(flextable)
library(reticulate)
library(recipes)   # for data preprocessing
# knitr::opts_chunk$set(echo = TRUE)

# opts_knit$set(root.dir = here())
opts_knit$set(root.dir = "~/Dropbox/ResearchProject/HeterogeneousAllocation")

opts_chunk$set(
  fig.align = "center", 
  fig.retina = 5,
  warning = FALSE, 
  message = FALSE,
  cache = FALSE, # <-- T
  cache.lazy = FALSE,
  echo = TRUE
  )
```


```{r}
#--- reticulate ---#
use_python("./myenv/bin/python")
use_virtualenv("./myenv/bin/activate_this.py")
```

```{python}
import econml

# Main imports
from econml.orf import DMLOrthoForest, DROrthoForest
from econml.dml import CausalForestDML
from econml.sklearn_extensions.linear_model import WeightedLassoCVWrapper, WeightedLasso, WeightedLassoCV

# Helper imports
import numpy as np
from itertools import product
from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, LogisticRegressionCV
import matplotlib.pyplot as plt

# %matplotlib inline
```


```{python}
# Treatment effect function
def exp_te(x):
    return np.exp(2*x[0])

 # DGP constants
np.random.seed(1234)
n = 1000
n_w = 30
support_size = 5
n_x = 1
# Outcome support
support_Y = np.random.choice(range(n_w), size=support_size, replace=False)
coefs_Y = np.random.uniform(0, 1, size=support_size)
epsilon_sample = lambda n: np.random.uniform(-1, 1, size=n)
# Treatment support
support_T = support_Y
coefs_T = np.random.uniform(0, 1, size=support_size)
eta_sample = lambda n: np.random.uniform(-1, 1, size=n) 

# Generate controls, covariates, treatments and outcomes
W = np.random.normal(0, 1, size=(n, n_w))
X = np.random.uniform(0, 1, size=(n, n_x))
# Heterogeneous treatment effects
TE = np.array([exp_te(x_i) for x_i in X])
# Define treatment
log_odds = np.dot(W[:, support_T], coefs_T) + eta_sample(n)
T_sigmoid = 1/(1 + np.exp(-log_odds))
T = np.array([np.random.binomial(1, p) for p in T_sigmoid])
# Define the outcome
Y = TE * T + np.dot(W[:, support_Y], coefs_Y) + epsilon_sample(n)

# ORF parameters and test data
subsample_ratio = 0.4
lambda_reg = np.sqrt(np.log(n_w) / (10 * subsample_ratio * n))
X_test = np.array(list(product(np.arange(0, 1, 0.01), repeat=n_x)))
``` 

```{python}
est = DROrthoForest(
    n_trees=200, min_leaf_size=10,
    max_depth=30, subsample_ratio=subsample_ratio,
    propensity_model = LogisticRegression(C=1/(X.shape[0]*lambda_reg), penalty='l1', solver='saga'),
    model_Y = Lasso(alpha=lambda_reg),
    propensity_model_final=LogisticRegression(C=1/(X.shape[0]*lambda_reg), penalty='l1', solver='saga'), 
    model_Y_final=WeightedLasso(alpha=lambda_reg)
)
```

```{python}
est.fit(Y, T, X=X, W=W)
```

```{python}
# Calculate treatment effects for the default treatment points T0=0 and T1=1
treatment_effects = est.effect(X_test)
```

```{r}
cate_effect <- tibble("X_test" = py$X_test, "te_pred" = py$treatment_effects)

cate_effect %>% 
  ggplot(aes(X_test, te_pred)) +
  geom_line() +
  labs(
    x = "Scale(Income)",
    y = "Orange Juice Elasticity",
    title = "Orange Juice Elasticity vs Income"
  )
```








































